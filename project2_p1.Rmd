---
title: "Project_2"
author: "Menghe Dou"
date: "3/3/2020"
output: pdf_document
---


## Read csv file

```{r cars}
getwd()
rm(list=ls())
setwd("/Users/joezhou/Desktop/2020 Spring/BA/project2")
getwd()

#read text file
data <- read.csv("house_cleaned.csv", header = TRUE, fileEncoding = "UTF-8-BOM")

```


## Scatter Plots

```{r plots}
plot(data$LotFrontage, data$SalePrice,xlab = "Lot Frontage", ylab = "Sale_Price")
plot(data$LotArea, data$SalePrice,xlab = "Lot Area", ylab = "Sale_Price")
plot(data$GrLivArea,data$SalePrice,xlab = "Living Area", ylab = "Sale_Price")
plot(data$Total_rooms,data$SalePrice,xlab = "Total rooms", ylab = "Sale_Price")
```

## Create dataset with each variable

```{r new column}
new_col1<-c(4,11)
linear_r1<-data[,new_col1]
```

## Linear regression

```{r }
y1<-lm(linear_r1$SalePrice~linear_r1$GrLivArea, data=linear_r1)
with(linear_r1, plot(linear_r1$GrLivArea, linear_r1$SalePrice, xlab = "Living Area", ylab = "Sale Price"))
abline(y1)
```

## Summary of dataset

```{r }
### linear_r1 ###

summary(linear_r1)

# correlation of data
p<-cor(linear_r1, use = "all.obs", method = "pearson")

# ANOVA Table
anova(y1)

# Summary of regression model
summary(y1)

# Confidence Interval
new_x<-c(max(linear_r1$GrLivArea))
obsn<-nrow(linear_r1)
mean_x<-mean(linear_r1$GrLivArea)

S_xx<-sum((linear_r1$GrLivArea)^2)-obsn*(mean_x)^2

new_y<-69.336*new_x+71901.486

# According to the regression summary
MSE <- 74386000000

# According to the T distribution table
t_test<-1.984

se_y<-sqrt(MSE*((1/obsn)+((new_x-mean_x)^2)/S_xx))

# CI
LI_CI<-new_y-t_test*se_y
UI_CI<-new_y+t_test*se_y

```

```{r}
#Prediction Interval
pe_y<-sqrt(MSE+(se_y)^2)

LI_PI <- new_y - t_test * pe_y
UI_PI <- new_y + t_test * pe_y

#PREDICTED_Y
y_hat <- 69.336*linear_r1$GrLivArea+71901.486

#residual
e <- linear_r1$SalePrice - y_hat

#Model Assumption
plot(y_hat,e,xlab="Y_hat",ylab = "e")
plot(linear_r1$GrLivArea,e,xlab="GrLivArea",ylab = "e")

num_obsn <- 1:obsn
plot(num_obsn,e,xlab="index",ylab = "e")

boxplot(e)
qqnorm(e)
qqline(e)

```

```{r}
#combineing dataset with residuals
new_data <- cbind(linear_r1,y1$fitted.values,y1$residuals)

names(new_data)[3:4] <- c("Fitted_values","residuals")

#standard errors for residuals

std_err = summary(y1)$sigma 

#finding expected value
n=nrow(new_data)
expected_value = sapply(1:n,function(k) std_err*qnorm((k-0.375)/(n+0.25)))

rho <- cor(expected_value,sort(y1$residuals))
```

```{r}
#modified-levene test

Group1 <- new_data[which((new_data$GrLivArea) < median(new_data$GrLivArea)), "residuals"]
Group2 <- new_data[which((new_data$GrLivArea) >= median(new_data$GrLivArea)), "residuals"]

#calculate mean absolute deviation
M1 <- median(Group1)
M2 <- median(Group2)

#mean absolute deviation
D1 <- sum(abs(Group1-M1)/length(Group1))
D2 <- sum(abs(Group2-M2)/length(Group2))

#pooled standard Error
s_levene <- sqrt((sum((abs(Group1-M1)-D1)^2) + sum((abs(Group2-M2)-D2)^2)) /(n-2))

#caculate absolute value of the test statistics
t_levene <- abs((D1-D2)/(s_levene-sqrt((1/length(Group1))+(1/length(Group2)))))

#find p-value for the above t-value
p_levene = pt(t_levene,n-2,lower.tail = FALSE)
# p = 0.2227238
# p > alpha, cannot reject H0, error variance is constant
```

